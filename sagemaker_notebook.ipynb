{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fa90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233dc4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import torch\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = int(config[\"Model Utilization\"][\"BATCH_SIZE\"])\n",
    "NUM_WORKERS = int(config[\"Model Utilization\"][\"NUM_WORKERS\"])\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75e1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_creation import create_model\n",
    "#Create model\n",
    "model, test_transforms = create_model(config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3112f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre exisiting model if applicable\n",
    "if config[\"Model Utilization\"].getboolean(\"load_exisiting_model\"):\n",
    "    folder_name = \"models\"\n",
    "    model_path = '/'.join((folder_name, config[\"Model Utilization\"][\"exisiting_model_name\"]))\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f828ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "#create custom transforms to give a more diverse set of training data\n",
    "training_transforms = torchvision.transforms.Compose([\n",
    "    #https://pytorch.org/vision/main/generated/torchvision.transforms.TrivialAugmentWide.html\n",
    "    torchvision.transforms.TrivialAugmentWide(), #change color, add noise, flip image, etc.\n",
    "    test_transforms, #original model transforms\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda3ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class S3Dataset(Dataset):\n",
    "    def __init__(self, bucket, prefix, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bucket (string): Bucket name.\n",
    "            prefix (string): Prefix path where images are stored in the bucket.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.s3 = boto3.client('s3')\n",
    "        self.bucket = bucket\n",
    "        self.prefix = prefix\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        # Load the list of files in the bucket\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.label_map = {}\n",
    "        paginator = self.s3.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "            for f in page.get('Contents', []):\n",
    "                file_path = f['Key']\n",
    "                if file_path.endswith('.jpg'):  # Filter to include only JPEG images\n",
    "                    self.files.append(file_path)\n",
    "                    # Split path and filter out empty strings\n",
    "                    parts = [part for part in file_path.replace(prefix, '').split('/') if part]\n",
    "                    if parts and len(parts) > 1:  # Check if there's at least a folder and a file\n",
    "                        folder_name = parts[0]\n",
    "                        if folder_name not in self.label_map:\n",
    "                            self.label_map[folder_name] = len(self.label_map)\n",
    "                        self.labels.append(self.label_map[folder_name])\n",
    "                    else:\n",
    "                        # Handle files directly under prefix or invalid paths by assigning a default label\n",
    "                        default_label = 'unknown'\n",
    "                        if default_label not in self.label_map:\n",
    "                            self.label_map[default_label] = len(self.label_map)\n",
    "                        self.labels.append(self.label_map[default_label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.files[idx]\n",
    "        try:\n",
    "            obj = self.s3.get_object(Bucket=self.bucket, Key=key)\n",
    "            image_data = obj['Body'].read()\n",
    "            #print(f\"Fetching image {key} from bucket {self.bucket}\")\n",
    "            #print(f\"Size of the data fetched: {len(image_data)} bytes\")\n",
    "            \n",
    "            if len(image_data) == 0:\n",
    "                raise ValueError(\"No data fetched; possibly the file does not exist or is empty.\")\n",
    "            \n",
    "            img = Image.open(io.BytesIO(image_data))\n",
    "            img = img.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            label = self.labels[idx]  # This will now be an integer\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching {key}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f6207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_setup import get_data_from_S3\n",
    "\n",
    "# Create an instance of your dataset\n",
    "s3_bucket = 'food101-images-for-classification'\n",
    "s3_prefix = 'data/food-101/images'\n",
    "dataset = S3Dataset(bucket=s3_bucket, prefix=s3_prefix, transform=transforms)\n",
    "\n",
    "train_data, test_data = get_data_from_S3(dataset,\n",
    "                 train_ratio=0.8,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 num_workers=0,\n",
    "                 train_transform=training_transforms,\n",
    "                 test_transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e65502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n",
      "Compose(\n",
      "    TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(training_transforms)\n",
    "print(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7d34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "loss = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ebffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SummaryWriter if we want to track results to TensorBoard\n",
    "if config[\"Model Utilization\"].getboolean(\"track_results\"):\n",
    "    writer = create_summary_writer(config[\"Model Utilization\"][\"experiment_model_name\"],\n",
    "                                    config[\"Model Utilization\"][\"experiment_information\"])\n",
    "else:\n",
    "    writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f310e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.17.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (1.66.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (4.25.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (72.1.0)\n",
      "Requirement already satisfied: six>1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->tensorboard) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5aea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny_vgg_5epochs.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [3:04:19<00:00, 17.70s/it]  \n",
      "Testing: 100%|██████████| 157/157 [29:23<00:00, 11.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "Train Loss: 4.4233, Train Accuracy: 0.0438, Train Top-5 Accuracy: 0.0438\n",
      "Test Loss: 4.3035, Test Accuracy: 0.0630, Test Top-5 Accuracy: 0.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [3:00:56<00:00, 17.37s/it]  \n",
      "Testing: 100%|██████████| 157/157 [28:41<00:00, 10.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:\n",
      "Train Loss: 4.0954, Train Accuracy: 0.1102, Train Top-5 Accuracy: 0.1102\n",
      "Test Loss: 4.0893, Test Accuracy: 0.1142, Test Top-5 Accuracy: 0.2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [3:04:55<00:00, 17.75s/it]  \n",
      "Testing: 100%|██████████| 157/157 [30:40<00:00, 11.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:\n",
      "Train Loss: 3.3757, Train Accuracy: 0.2788, Train Top-5 Accuracy: 0.2788\n",
      "Test Loss: 4.3424, Test Accuracy: 0.1026, Test Top-5 Accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [30:10<00:00, 11.53s/it]it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:\n",
      "Train Loss: 2.2407, Train Accuracy: 0.6174, Train Top-5 Accuracy: 0.6174\n",
      "Test Loss: 5.1784, Test Accuracy: 0.0794, Test Top-5 Accuracy: 0.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [3:08:00<00:00, 18.05s/it]  \n",
      "Testing: 100%|██████████| 157/157 [31:41<00:00, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:\n",
      "Train Loss: 1.4830, Train Accuracy: 0.8860, Train Top-5 Accuracy: 0.8860\n",
      "Test Loss: 5.7418, Test Accuracy: 0.0656, Test Top-5 Accuracy: 0.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from model_utilization import train\n",
    "#Train if applicable\n",
    "print(config[\"Model Utilization\"][\"model_save_name\"])\n",
    "if config[\"Model Utilization\"].getboolean(\"train\"):\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_data,\n",
    "                    test_dataloader=test_data,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss,\n",
    "                    epochs=int(config[\"Model Utilization\"][\"epochs\"]),\n",
    "                    device=device,\n",
    "                    writer=writer,\n",
    "                    verbose = config[\"Model Utilization\"].getboolean(\"verbose\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5aeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model tiny_vgg_5epochs.pth\n"
     ]
    }
   ],
   "source": [
    "from model_creation import save_model\n",
    "#Save if applicable\n",
    "if config[\"Model Utilization\"].getboolean(\"save_model\"):\n",
    "    model_name = config[\"Model Utilization\"][\"model_save_name\"]\n",
    "    print(f\"Saving model {model_name}\")\n",
    "    save_model(model, \"models\", model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a124f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7e1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
