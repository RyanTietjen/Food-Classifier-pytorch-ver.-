{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d71df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ryan Tietjen\n",
    "Sep 2024\n",
    "Notebook for use in AWS SageMaker\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233dc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import torch\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = int(config[\"Model Utilization\"][\"BATCH_SIZE\"])\n",
    "NUM_WORKERS = int(config[\"Model Utilization\"][\"NUM_WORKERS\"])\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e1c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_creation import create_model\n",
    "#Create model\n",
    "model, test_transforms = create_model(config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre exisiting model if applicable\n",
    "if config[\"Model Utilization\"].getboolean(\"load_exisiting_model\"):\n",
    "    folder_name = \"models\"\n",
    "    model_path = '/'.join((folder_name, config[\"Model Utilization\"][\"exisiting_model_name\"]))\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "#create custom transforms to give a more diverse set of training data\n",
    "training_transforms = torchvision.transforms.Compose([\n",
    "    #https://pytorch.org/vision/main/generated/torchvision.transforms.TrivialAugmentWide.html\n",
    "    torchvision.transforms.TrivialAugmentWide(), #change color, add noise, flip image, etc.\n",
    "    test_transforms, #original model transforms\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class S3Dataset(Dataset):\n",
    "    def __init__(self, bucket, prefix, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bucket (string): Bucket name.\n",
    "            prefix (string): Prefix path where images are stored in the bucket.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.s3 = boto3.client('s3')\n",
    "        self.bucket = bucket\n",
    "        self.prefix = prefix\n",
    "        self.transform = transform or transforms.ToTensor()\n",
    "\n",
    "        # Load the list of files in the bucket\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.label_map = {}\n",
    "        paginator = self.s3.get_paginator('list_objects_v2')\n",
    "        \n",
    "        for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "            for f in page.get('Contents', []):\n",
    "                file_path = f['Key']\n",
    "                if file_path.endswith('.jpg'):  # Filter to include only JPEG images\n",
    "                    self.files.append(file_path)\n",
    "                    # Split path and filter out empty strings\n",
    "                    parts = [part for part in file_path.replace(prefix, '').split('/') if part]\n",
    "                    if parts and len(parts) > 1:  # Check if there's at least a folder and a file\n",
    "                        folder_name = parts[0]\n",
    "                        if folder_name not in self.label_map:\n",
    "                            self.label_map[folder_name] = len(self.label_map)\n",
    "                        self.labels.append(self.label_map[folder_name])\n",
    "                    else:\n",
    "                        # Handle files directly under prefix or invalid paths by assigning a default label\n",
    "                        default_label = 'unknown'\n",
    "                        if default_label not in self.label_map:\n",
    "                            self.label_map[default_label] = len(self.label_map)\n",
    "                        self.labels.append(self.label_map[default_label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.files[idx]\n",
    "        try:\n",
    "            obj = self.s3.get_object(Bucket=self.bucket, Key=key)\n",
    "            image_data = obj['Body'].read()\n",
    "            #print(f\"Fetching image {key} from bucket {self.bucket}\")\n",
    "            #print(f\"Size of the data fetched: {len(image_data)} bytes\")\n",
    "            \n",
    "            if len(image_data) == 0:\n",
    "                raise ValueError(\"No data fetched; possibly the file does not exist or is empty.\")\n",
    "            \n",
    "            img = Image.open(io.BytesIO(image_data))\n",
    "            img = img.convert(\"RGB\")  # Ensure image is in RGB format\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            label = self.labels[idx]  # This will now be an integer\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching {key}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_setup import get_data_from_S3\n",
    "\n",
    "# Create an instance of your dataset\n",
    "s3_bucket = 'food101-images-for-classification'\n",
    "s3_prefix = 'data/food-101/images'\n",
    "dataset = S3Dataset(bucket=s3_bucket, prefix=s3_prefix, transform=transforms)\n",
    "\n",
    "train_data, test_data = get_data_from_S3(dataset,\n",
    "                 train_ratio=0.8,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 num_workers=0,\n",
    "                 train_transform=training_transforms,\n",
    "                 test_transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(training_transforms)\n",
    "print(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "loss = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ebffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SummaryWriter if we want to track results to TensorBoard\n",
    "if config[\"Model Utilization\"].getboolean(\"track_results\"):\n",
    "    writer = create_summary_writer(config[\"Model Utilization\"][\"experiment_model_name\"],\n",
    "                                    config[\"Model Utilization\"][\"experiment_information\"])\n",
    "else:\n",
    "    writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f310e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5aea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utilization import train\n",
    "#Train if applicable\n",
    "print(config[\"Model Utilization\"][\"model_save_name\"])\n",
    "if config[\"Model Utilization\"].getboolean(\"train\"):\n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_data,\n",
    "                    test_dataloader=test_data,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss,\n",
    "                    epochs=int(config[\"Model Utilization\"][\"epochs\"]),\n",
    "                    device=device,\n",
    "                    writer=writer,\n",
    "                    verbose = config[\"Model Utilization\"].getboolean(\"verbose\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d5aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_creation import save_model\n",
    "#Save if applicable\n",
    "if config[\"Model Utilization\"].getboolean(\"save_model\"):\n",
    "    model_name = config[\"Model Utilization\"][\"model_save_name\"]\n",
    "    print(f\"Saving model {model_name}\")\n",
    "    save_model(model, \"models\", model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a124f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7e1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
